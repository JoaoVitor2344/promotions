## Fase 1: Funda칞칚o e Setup

**Dura칞칚o Estimada:** 1-2 dias  
**Objetivo:** Montar o esqueleto do projeto, configurar todas as ferramentas essenciais e garantir que as conex칫es b치sicas estejam funcionando.

### Milestone 1.1: Estrutura do Projeto

- [x] Iniciar um novo projeto Node.js (`npm init`)
- [x] Criar a estrutura de pastas principal conforme o documento de arquitetura
- [x] Iniciar o reposit칩rio Git (`git init`) e criar o primeiro commit

### Milestone 1.2: Configura칞칚o dos Bancos de Dados

- [x] Instalar e configurar o PostgreSQL localmente
- [x] Instalar o Prisma (`npm install prisma --save-dev`) e inicializ치-lo (`npx prisma init`)
- [x] Definir o modelo de dados inicial no `schema.prisma` (ex: uma tabela Promotion para guardar o hist칩rico)
- [x] Executar a primeira migra칞칚o para criar a tabela no banco (`npx prisma migrate dev`)
- [ ] Instalar e configurar o Redis localmente

### Milestone 1.3: Configura칞칚o do Ambiente

- [x] Instalar o dotenv (`npm install dotenv`)
- [x] Criar o arquivo `.env.example` com todas as vari치veis necess치rias
- [x] Criar o arquivo `.env` (e adicion치-lo ao `.gitignore`)
- [x] Preencher o `.env` com as credenciais dos bancos de dados e o token do bot do Telegram

### Milestone 1.4: Conex칚o com Telegram

- [x] Criar o m칩dulo `telegramService.js`
- [x] Implementar uma fun칞칚o simples `enviarMensagemTeste()` que envia um "Ol치, Mundo!" para o seu canal, para validar o token e a conex칚o

---

## Fase 2: Constru칞칚o do MVP - O Fluxo Central

**Dura칞칚o Estimada:** 3-5 dias  
**Objetivo:** Criar a primeira vers칚o funcional do bot, capaz de extrair uma promo칞칚o e public치-la, ainda sem a complexidade da fila de prioridade.

### Milestone 2.1: Desenvolvimento do Scraper (Vigia)

- [x] Instalar o Playwright (`npm install playwright`)
- [x] Desenvolver a l칩gica no `pelandoScrapper.js` para:
  - Abrir a p치gina do Pelando
  - Extrair o t칤tulo, pre칞o, loja e link da primeira promo칞칚o na p치gina
- [x] Criar uma fun칞칚o principal `searchPromotions()` que retorna os dados extra칤dos

### Milestone 2.2: Implementa칞칚o dos Processadores (Cleaner & Monetizer)

- [ ] Criar a fun칞칚o `limparLink()` em `linkCleaner.js` que resolve o redirecionamento
- [ ] Criar a fun칞칚o `monetizarLink()` em `affiliateMonetizer.js` que usa uma l칩gica if/else para adicionar o ID de afiliado correto com base na loja

### Milestone 2.3: Integra칞칚o do Fluxo Simples

- [ ] Criar um script de teste `test-flow.js` que:
  - Chama `searchPromotions()`
  - Passa o resultado para `limparLink()`
  - Passa o resultado para `monetizarLink()`
  - Usa o `telegramService` para enviar a promo칞칚o formatada para o canal
- [ ] Refatorar e garantir que cada m칩dulo funcione em conjunto

---

## Fase 3: Implementa칞칚o da Intelig칡ncia e Resili칡ncia

**Dura칞칚o Estimada:** 2-4 dias  
**Objetivo:** Transformar o fluxo simples em um sistema robusto, introduzindo a fila de prioridades e a arquitetura de workers.

### Milestone 3.1: Integra칞칚o com Redis

- [ ] Criar o `redisClient.js` para gerenciar a conex칚o
- [ ] Desenvolver o `promotionQueue.js` com duas fun칞칫es principais:
  - `adicionarPromocao(promocao, prioridade)`
  - `buscarProximaPromocao()`

### Milestone 3.2: Refatora칞칚o para a Arquitetura de Fila

- [ ] Modificar o Scraper para, em vez de retornar os dados, adicion치-los  fila do Redis usando `adicionarPromocao()`
- [ ] Criar o ponto de entrada `worker.js`, que roda em um loop cont칤nuo, chama `buscarProximaPromocao()` e, se houver uma, executa o fluxo de limpeza, monetiza칞칚o e envio
- [ ] Criar o ponto de entrada `scheduler.js`, que usa node-cron para chamar o Scraper no intervalo definido no `.env`

### Milestone 3.3: Implementa칞칚o do Analisador de Prioridade

- [ ] Criar a fun칞칚o `analisarPrioridade(promocao)` que implementa as regras de if/else que definimos (baseado em palavras-chave, desconto, etc.)
- [ ] Integrar o analisador no Scraper, para que a prioridade seja calculada antes de adicionar a promo칞칚o  fila

---

## 游 Fase 4: Otimiza칞칚o e Expans칚o

**Dura칞칚o:** Cont칤nuo  
**Objetivo:** Melhorar a qualidade do sistema, adicionar novas funcionalidades e garantir que ele seja f치cil de manter.

### Milestone 4.1: Melhorias e Logs

- [ ] Implementar o salvamento de cada promo칞칚o postada no banco de dados PostgreSQL para criar um hist칩rico
- [ ] Adicionar um sistema de logs (ex: usando a biblioteca winston) para registrar erros e atividades importantes no banco de dados ou em arquivos
- [ ] Refinar o scraper para ser mais resiliente a pequenas mudan칞as no layout do site

### Milestone 4.2: Expans칚o de Funcionalidades

- [ ] (Opcional) Integrar o `geminiService.js` para usar a IA na an치lise de prioridade
- [ ] Desenvolver um novo scraper para uma segunda fonte (ex: `promobitScraper.js`)
- [ ] Criar um painel de controle simples (dashboard) para visualizar estat칤sticas b치sicas a partir dos dados do PostgreSQL
